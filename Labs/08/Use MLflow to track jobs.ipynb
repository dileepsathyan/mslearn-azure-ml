{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run a training script as a command job\n",
        "\n",
        "You can use the Python SDK for Azure Machine Learning to submit scripts as command jobs. By using jobs, you can easily keep track of the input parameters and outputs when training a machine learning model.\n",
        "\n",
        "## Before you start\n",
        "\n",
        "You'll need the latest version of the **azure-ai-ml** package to run the code in this notebook. Run the cell below to verify that it is installed.\n",
        "\n",
        "> **Note**:\n",
        "> If the **azure-ai-ml** package is not installed, run `pip install azure-ai-ml` to install it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Name: azure-ai-ml\n",
            "Version: 1.30.0\n",
            "Summary: Microsoft Azure Machine Learning Client Library for Python\n",
            "Home-page: https://github.com/Azure/azure-sdk-for-python\n",
            "Author: Microsoft Corporation\n",
            "Author-email: azuresdkengsysadmins@microsoft.com\n",
            "License: MIT License\n",
            "Location: c:\\Users\\Dsathyan\\Documents\\GitHub\\mslearn-azure-ml\\Labs\\.azureml-venv\\Lib\\site-packages\n",
            "Requires: azure-common, azure-core, azure-mgmt-core, azure-monitor-opentelemetry, azure-storage-blob, azure-storage-file-datalake, azure-storage-file-share, colorama, isodate, jsonschema, marshmallow, pydash, pyjwt, pyyaml, strictyaml, tqdm, typing-extensions\n",
            "Required-by: \n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip show azure-ai-ml"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "With the required SDK packages installed, now you're ready to connect to your workspace.\n",
        "\n",
        "To connect to a workspace, we need identifier parameters - a subscription ID, resource group name, and workspace name. Since you're working with a compute instance, managed by Azure Machine Learning, you can use the default values to connect to the workspace."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1663753569264
        }
      },
      "outputs": [],
      "source": [
        "from azure.identity import DefaultAzureCredential, InteractiveBrowserCredential\n",
        "from azure.ai.ml import MLClient\n",
        "\n",
        "try:\n",
        "    credential = DefaultAzureCredential()\n",
        "    # Check if given credential can get token successfully.\n",
        "    credential.get_token(\"https://management.azure.com/.default\")\n",
        "except Exception as ex:\n",
        "    # Fall back to InteractiveBrowserCredential in case DefaultAzureCredential not work\n",
        "    credential = InteractiveBrowserCredential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found the config file in: .\\config.json\n",
            "Class DeploymentTemplateOperations: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
          ]
        }
      ],
      "source": [
        "# Get a handle to workspace\n",
        "ml_client = MLClient.from_config(credential=credential)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom tracking with MLflow\n",
        "\n",
        "When running a script as a job you can use MLflow in your training script to track the model. MLflow allows you to track any custom parameters, metrics, or artifacts you want to store with your job output.\n",
        "\n",
        "Run the following cells to create the **train-model-mlflow.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. \n",
        "\n",
        "Review the code below to find that the script will import `mlflow` and log:\n",
        "\n",
        "- The regularization rate as a **parameter**. \n",
        "- The accuracy and AUC as **metrics**.\n",
        "- The plotted ROC curve as an **artifact**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "src folder created\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# create a folder for the script files\n",
        "script_folder = 'src'\n",
        "os.makedirs(script_folder, exist_ok=True)\n",
        "print(script_folder, 'folder created')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model-mlflow.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model-mlflow.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    # evaluate model\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    mlflow.log_param(\"Regularization rate\", reg_rate)\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "    mlflow.log_metric(\"Accuracy\", acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "    mlflow.log_metric(\"AUC\", auc)\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\")\n",
        "    mlflow.log_artifact(\"ROC-Curve.png\")    \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you can submit the script as a command job.\n",
        "\n",
        "Run the cell below to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Class AutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class AutoDeleteConditionSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseAutoDeleteSettingSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class IntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class ProtectionLevelSchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "Class BaseIntellectualPropertySchema: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
            "\u001b[32mUploading src (0.54 MBs): 100%|##########| 541577/541577 [00:00<00:00, 551171.61it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/affable_pear_td1f10gs7z?wsid=/subscriptions/38245d22-4620-4106-9d08-a07ed74df31e/resourcegroups/rg-dp100-l/workspaces/mlw-dp100-l&tid=ddd22570-6918-428b-8086-9e65a1663864\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-mlflow.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-mlflow\",\n",
        "    experiment_name=\"diabetes-training\", \n",
        "    tags={\"model_type\": \"LogisticRegression\"}\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the Studio, navigate to the **diabetes-train-mlflow** job to explore the overview of the command job you ran:\n",
        "\n",
        "- Find the logged parameters in the **Overview** tab, under **Params**.\n",
        "- Find the logged metrics in the **Metrics** tab.\n",
        "- Find the logged artifacts in the **Images** tab (specifically for images), and in the **Outputs + logs** tab (all files)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Autologging with MLflow\n",
        "\n",
        "Instead of using custom logging, MLflow can also automatically log any parameters, metrics, and artifacts. Autologging with MLflow requires only one line of code.\n",
        "\n",
        "Run the following cell to create the **train-model-autolog.py** script in the **src** folder. The script trains a classification model by using the **diabetes.csv** file in the same folder, which is passed as an argument. \n",
        "\n",
        "Review the code below to find that the script will import `mlflow` and enables autologging with the line: \n",
        "\n",
        "`mlflow.autolog()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting src/train-model-autolog.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile $script_folder/train-model-autolog.py\n",
        "# import libraries\n",
        "import mlflow\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def main(args):\n",
        "    # enable autologging\n",
        "    mlflow.autolog()\n",
        "\n",
        "    # read data\n",
        "    df = get_data(args.training_data)\n",
        "\n",
        "    # split data\n",
        "    X_train, X_test, y_train, y_test = split_data(df)\n",
        "\n",
        "    # train model\n",
        "    model = train_model(args.reg_rate, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    eval_model(model, X_test, y_test)\n",
        "\n",
        "# function that reads the data\n",
        "def get_data(path):\n",
        "    print(\"Reading data...\")\n",
        "    df = pd.read_csv(path)\n",
        "    \n",
        "    return df\n",
        "\n",
        "# function that splits the data\n",
        "def split_data(df):\n",
        "    print(\"Splitting data...\")\n",
        "    X, y = df[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness',\n",
        "    'SerumInsulin','BMI','DiabetesPedigree','Age']].values, df['Diabetic'].values\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# function that trains the model\n",
        "def train_model(reg_rate, X_train, X_test, y_train, y_test):\n",
        "    print(\"Training model...\")\n",
        "    model = LogisticRegression(C=1/reg_rate, solver=\"liblinear\").fit(X_train, y_train)\n",
        "\n",
        "    return model\n",
        "\n",
        "# function that evaluates the model\n",
        "def eval_model(model, X_test, y_test):\n",
        "    # calculate accuracy\n",
        "    y_hat = model.predict(X_test)\n",
        "    acc = np.average(y_hat == y_test)\n",
        "    print('Accuracy:', acc)\n",
        "\n",
        "    # calculate AUC\n",
        "    y_scores = model.predict_proba(X_test)\n",
        "    auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "    print('AUC: ' + str(auc))\n",
        "\n",
        "    # plot ROC curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "    fig = plt.figure(figsize=(6, 4))\n",
        "    # Plot the diagonal 50% line\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    # Plot the FPR and TPR achieved by our model\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.savefig(\"ROC-Curve.png\") \n",
        "\n",
        "def parse_args():\n",
        "    # setup arg parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # add arguments\n",
        "    parser.add_argument(\"--training_data\", dest='training_data',\n",
        "                        type=str)\n",
        "    parser.add_argument(\"--reg_rate\", dest='reg_rate',\n",
        "                        type=float, default=0.01)\n",
        "\n",
        "    # parse args\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # return args\n",
        "    return args\n",
        "\n",
        "# run script\n",
        "if __name__ == \"__main__\":\n",
        "    # add space in logs\n",
        "    print(\"\\n\\n\")\n",
        "    print(\"*\" * 60)\n",
        "\n",
        "    # parse args\n",
        "    args = parse_args()\n",
        "\n",
        "    # run main function\n",
        "    main(args)\n",
        "\n",
        "    # add space in logs\n",
        "    print(\"*\" * 60)\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, you can submit the script as a command job.\n",
        "\n",
        "Run the cell below to train the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32mUploading src (0.54 MBs): 100%|##########| 541573/541573 [00:00<00:00, 675994.24it/s]\n",
            "\u001b[39m\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Monitor your job at https://ml.azure.com/runs/neat_carnival_5bhw6zcpp4?wsid=/subscriptions/38245d22-4620-4106-9d08-a07ed74df31e/resourcegroups/rg-dp100-l/workspaces/mlw-dp100-l&tid=ddd22570-6918-428b-8086-9e65a1663864\n"
          ]
        }
      ],
      "source": [
        "from azure.ai.ml import command\n",
        "\n",
        "# configure job\n",
        "\n",
        "job = command(\n",
        "    code=\"./src\",\n",
        "    command=\"python train-model-autolog.py --training_data diabetes.csv\",\n",
        "    environment=\"AzureML-sklearn-0.24-ubuntu18.04-py37-cpu@latest\",\n",
        "    compute=\"aml-cluster\",\n",
        "    display_name=\"diabetes-train-autolog\",\n",
        "    experiment_name=\"diabetes-training\"\n",
        "    )\n",
        "\n",
        "# submit job\n",
        "returned_job = ml_client.create_or_update(job)\n",
        "aml_url = returned_job.studio_url\n",
        "print(\"Monitor your job at\", aml_url)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the Studio, navigate to the **diabetes-train-autolog** job to explore the overview of the command job you ran:\n",
        "\n",
        "- Find the logged parameters in the **Overview** tab, under **Params**.\n",
        "- Find the logged metrics in the **Metrics** tab.\n",
        "- Find the logged artifacts in the **Images** tab (specifically for images), and in the **Outputs + logs** tab (all files, including the model files)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Use MLflow to view and search for experiments\n",
        "\n",
        "The Azure Machine Learning Studio is an easy-to-use UI to view and compare job runs. Alternatively, you can use MLflow to view experiment jobs. \n",
        "\n",
        "To list the jobs in the workspace, use the following command to list the experiments in the workspace:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "before: file:///c:/Users/Dsathyan/Documents/GitHub/mslearn-azure-ml/Labs/08/mlruns\n"
          ]
        }
      ],
      "source": [
        "# Example â€” check the current MLFlow URI first, then set to your workspace's tracking URI\n",
        "import mlflow\n",
        "print(\"before:\", mlflow.get_tracking_uri())\n",
        "\n",
        "# Replace <workspace_tracking_uri> with the workspace tracking endpoint (if you have it)\n",
        "mlflow.set_tracking_uri(\"<workspace_tracking_uri>\")\n",
        "print(\"after:\", mlflow.get_tracking_uri())\n",
        "\n",
        "# now search\n",
        "experiments = mlflow.search_experiments()\n",
        "for e in experiments:\n",
        "    print(e.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Default\n"
          ]
        }
      ],
      "source": [
        "import mlflow\n",
        "experiments = mlflow.search_experiments()\n",
        "for exp in experiments:\n",
        "    print(exp.name)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To retrieve a specific experiment, you can get it by its name:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "experiment_name = \"diabetes-training\"\n",
        "exp = mlflow.get_experiment_by_name(experiment_name)\n",
        "print(exp)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using an experiment name, you can retrieve all jobs of that experiment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'experiment_id'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mlflow.search_runs(\u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment_id\u001b[49m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'experiment_id'"
          ]
        }
      ],
      "source": [
        "mlflow.search_runs(exp.experiment_id)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To more easily compare job runs and outputs, you can configure the search to order the results. For example, the following cell orders the results by `start_time`, and only shows a maximum of `2` results: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'experiment_id'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mlflow.search_runs(\u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment_id\u001b[49m, order_by=[\u001b[33m\"\u001b[39m\u001b[33mstart_time DESC\u001b[39m\u001b[33m\"\u001b[39m], max_results=\u001b[32m2\u001b[39m)\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'experiment_id'"
          ]
        }
      ],
      "source": [
        "mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=2)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can even create a query to filter the runs. Filter query strings are written with a simplified version of the SQL `WHERE` clause. \n",
        "\n",
        "To filter, you can use two classes of comparators:\n",
        "\n",
        "- Numeric comparators (metrics): =, !=, >, >=, <, and <=.\n",
        "- String comparators (params, tags, and attributes): = and !=.\n",
        "\n",
        "Learn more about [how to track experiments with MLflow](https://learn.microsoft.com/azure/machine-learning/how-to-track-experiments-mlflow)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'experiment_id'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m\"\u001b[39m\u001b[33mmetrics.AUC > 0.8 and tags.model_type = \u001b[39m\u001b[33m'\u001b[39m\u001b[33mLogisticRegression\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m mlflow.search_runs(\u001b[43mexp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexperiment_id\u001b[49m, filter_string=query)\n",
            "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'experiment_id'"
          ]
        }
      ],
      "source": [
        "query = \"metrics.AUC > 0.8 and tags.model_type = 'LogisticRegression'\"\n",
        "mlflow.search_runs(exp.experiment_id, filter_string=query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": ".azureml-venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
